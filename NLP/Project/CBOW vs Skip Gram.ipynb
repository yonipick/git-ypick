{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yoni\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\Yoni\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "#import zipfile\n",
    "from matplotlib import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn.manifold import TSNE\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Game Of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book One of A Song of Ice and Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By George R. R. Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROLOGUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"We should start back,\" Gared urged as the woo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                                 A Game Of Thrones \n",
       "1                Book One of A Song of Ice and Fire \n",
       "2                            By George R. R. Martin \n",
       "3                                          PROLOGUE \n",
       "4  \"We should start back,\" Gared urged as the woo..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('001ssb.txt',header=None, delimiter = '\\n', quoting = 3)\n",
    "dataset.rename(columns={\"0\": \"Lines_Numbers\"})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yoni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, dataset.size):\n",
    "    line = re.sub('[^a-zA-Z]', ' ', dataset[0][i])\n",
    "    line = line.lower()\n",
    "    line = line.split()\n",
    "    #ps = PorterStemmer()\n",
    "    line = [word for word in line if not word in set(stopwords.words('english'))]\n",
    "    line = ' '.join(line)\n",
    "    corpus.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brown fox jumped lazy dog', 'chicken cross road', 'like flying plane']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like flying on a plane\n",
      "['brown fox jumped lazy dog', 'chicken cross road', 'like flying plane']\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][2])\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "['brown', 'chicken', 'cross', 'dog', 'flying', 'fox', 'jumped', 'lazy', 'like', 'plane', 'road']\n"
     ]
    }
   ],
   "source": [
    "print (len(cv.vocabulary_))\n",
    "print(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0 1 1 1 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#one hot vectoer\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.preprocessing.sequence.skipgrams(sequence=dataset,vocabulary_size=len(cv.vocabulary_),negative_samples=1,\n",
    "                                          window_size=1, seed =5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Game Of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book One of A Song of Ice and Fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By George R. R. Martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROLOGUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"We should start back,\" Gared urged as the woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dead.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Do the dead frighten you?\" Ser Waymar Royce a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gared did not rise to the bait. He was an old ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Dead is dead,\" he said. \"We have no business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Are they dead?\" Royce asked softly. \"What pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Will saw them,\" Gared said. \"If he says they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Will had known they would drag him into the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>than sooner. \"My mother told me that dead men ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"My wet nurse said the same thing, Will,\" Royc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tit. There are things to be learned even from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"We have a long ride before us,\" Gared pointed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ser Waymar Royce glanced at the sky with disin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>unmanned by the dark, Gared?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Will could see the tightness around Gared's mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pressed anger in his eyes under the thick blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Night's Watch, man and boy, and he was not acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>that. Under the wounded pride, Will could sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nervous tension that came perilous close to fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Will shared his unease. He had been four years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the old stories had come rushing back, and his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>afterward. He was a veteran of a hundred rangi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>southron called the haunted forest had no more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Until tonight. Something was different tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rise. Nine days they had been riding, north an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19568</th>\n",
       "      <td>through the firefall Dany heard women shriek a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19569</th>\n",
       "      <td>Only death can pay for life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19570</th>\n",
       "      <td>And there came a second crack, loud and sharp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19571</th>\n",
       "      <td>her and the pyre shifted, the logs exploding a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19572</th>\n",
       "      <td>of frightened horses, and the voices of the Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19573</th>\n",
       "      <td>calling her name and cursing. No, she wanted t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19574</th>\n",
       "      <td>The fire is mine. I am Daenerys Stormborn, dau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19575</th>\n",
       "      <td>dragons, mother of dragons, don't you see? Don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19576</th>\n",
       "      <td>reached thirty feet into the sky, the pyre col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19577</th>\n",
       "      <td>forward into the firestorm, calling to her chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19578</th>\n",
       "      <td>The third crack was as loud and sharp as the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19579</th>\n",
       "      <td>When the fire died at last and the ground beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19580</th>\n",
       "      <td>her amidst the ashes, surrounded by blackened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19581</th>\n",
       "      <td>man and woman and stallion. She was naked, cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19582</th>\n",
       "      <td>hair all crisped away . . . yet she was unhurt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19583</th>\n",
       "      <td>The cream-and-gold dragon was suckling at her ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19584</th>\n",
       "      <td>cradled them close. The black-and-scarlet beas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19585</th>\n",
       "      <td>coiled under her chin. When it saw Jorah, it r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19586</th>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19587</th>\n",
       "      <td>Wordless, the knight fell to his knees. The me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19588</th>\n",
       "      <td>lay his arakh at her feet. \"Blood of my blood,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19589</th>\n",
       "      <td>\"Blood of my blood,\" she heard Aggo echo. \"Blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19590</th>\n",
       "      <td>And after them came her handmaids, and then th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19591</th>\n",
       "      <td>and Dany had only to look at their eyes to kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19592</th>\n",
       "      <td>forever, hers as they had never been Drogo's.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19593</th>\n",
       "      <td>As Daenerys Targaryen rose to her feet, her bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19594</th>\n",
       "      <td>nostrils. The other two pulled away from her b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19595</th>\n",
       "      <td>unfolding and stirring the air, and for the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19596</th>\n",
       "      <td>music of dragons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19597</th>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19598 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0\n",
       "0                                     A Game Of Thrones \n",
       "1                    Book One of A Song of Ice and Fire \n",
       "2                                By George R. R. Martin \n",
       "3                                              PROLOGUE \n",
       "4      \"We should start back,\" Gared urged as the woo...\n",
       "5                                                dead.\" \n",
       "6      \"Do the dead frighten you?\" Ser Waymar Royce a...\n",
       "7      Gared did not rise to the bait. He was an old ...\n",
       "8      \"Dead is dead,\" he said. \"We have no business ...\n",
       "9      \"Are they dead?\" Royce asked softly. \"What pro...\n",
       "10     \"Will saw them,\" Gared said. \"If he says they ...\n",
       "11     Will had known they would drag him into the qu...\n",
       "12     than sooner. \"My mother told me that dead men ...\n",
       "13     \"My wet nurse said the same thing, Will,\" Royc...\n",
       "14     tit. There are things to be learned even from ...\n",
       "15                                                     1\n",
       "16     \"We have a long ride before us,\" Gared pointed...\n",
       "17     Ser Waymar Royce glanced at the sky with disin...\n",
       "18                        unmanned by the dark, Gared?\" \n",
       "19     Will could see the tightness around Gared's mo...\n",
       "20     pressed anger in his eyes under the thick blac...\n",
       "21     Night's Watch, man and boy, and he was not acc...\n",
       "22     that. Under the wounded pride, Will could sens...\n",
       "23     nervous tension that came perilous close to fe...\n",
       "24     Will shared his unease. He had been four years...\n",
       "25     the old stories had come rushing back, and his...\n",
       "26     afterward. He was a veteran of a hundred rangi...\n",
       "27     southron called the haunted forest had no more...\n",
       "28     Until tonight. Something was different tonight...\n",
       "29     rise. Nine days they had been riding, north an...\n",
       "...                                                  ...\n",
       "19568  through the firefall Dany heard women shriek a...\n",
       "19569                      Only death can pay for life. \n",
       "19570  And there came a second crack, loud and sharp ...\n",
       "19571  her and the pyre shifted, the logs exploding a...\n",
       "19572  of frightened horses, and the voices of the Do...\n",
       "19573  calling her name and cursing. No, she wanted t...\n",
       "19574  The fire is mine. I am Daenerys Stormborn, dau...\n",
       "19575  dragons, mother of dragons, don't you see? Don...\n",
       "19576  reached thirty feet into the sky, the pyre col...\n",
       "19577  forward into the firestorm, calling to her chi...\n",
       "19578  The third crack was as loud and sharp as the b...\n",
       "19579  When the fire died at last and the ground beca...\n",
       "19580  her amidst the ashes, surrounded by blackened ...\n",
       "19581  man and woman and stallion. She was naked, cov...\n",
       "19582   hair all crisped away . . . yet she was unhurt. \n",
       "19583  The cream-and-gold dragon was suckling at her ...\n",
       "19584  cradled them close. The black-and-scarlet beas...\n",
       "19585  coiled under her chin. When it saw Jorah, it r...\n",
       "19586                                                570\n",
       "19587  Wordless, the knight fell to his knees. The me...\n",
       "19588  lay his arakh at her feet. \"Blood of my blood,...\n",
       "19589  \"Blood of my blood,\" she heard Aggo echo. \"Blo...\n",
       "19590  And after them came her handmaids, and then th...\n",
       "19591  and Dany had only to look at their eyes to kno...\n",
       "19592     forever, hers as they had never been Drogo's. \n",
       "19593  As Daenerys Targaryen rose to her feet, her bl...\n",
       "19594  nostrils. The other two pulled away from her b...\n",
       "19595  unfolding and stirring the air, and for the fi...\n",
       "19596                                 music of dragons. \n",
       "19597                                                571\n",
       "\n",
       "[19598 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['he', 'is', 'a', 'king'], ['she', 'is', 'a', 'queen'], ['he', 'is', 'a', 'man'], ['she', 'is', 'a', 'woman'], ['warsaw', 'is', 'poland', 'capital'], ['berlin', 'is', 'germany', 'capital'], ['paris', 'is', 'france', 'capital']]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_corpus(corpus):\n",
    "    tokens = [x.split() for x in corpus]\n",
    "    return tokens\n",
    "\n",
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he': 0, 'is': 1, 'a': 2, 'king': 3, 'she': 4, 'queen': 5, 'man': 6, 'woman': 7, 'warsaw': 8, 'poland': 9, 'capital': 10, 'berlin': 11, 'germany': 12, 'paris': 13, 'france': 14}\n",
      "############################\n",
      "{0: 'he', 1: 'is', 2: 'a', 3: 'king', 4: 'she', 5: 'queen', 6: 'man', 7: 'woman', 8: 'warsaw', 9: 'poland', 10: 'capital', 11: 'berlin', 12: 'germany', 13: 'paris', 14: 'france'}\n",
      "############################\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for sentence in tokenized_corpus:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(word2idx)\n",
    "print('############################')\n",
    "print(idx2word)\n",
    "print('############################')\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 0  2]\n",
      " [ 1  0]\n",
      " [ 1  2]\n",
      " [ 1  3]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  3]\n",
      " [ 3  1]\n",
      " [ 3  2]\n",
      " [ 4  1]\n",
      " [ 4  2]\n",
      " [ 1  4]\n",
      " [ 1  2]\n",
      " [ 1  5]\n",
      " [ 2  4]\n",
      " [ 2  1]\n",
      " [ 2  5]\n",
      " [ 5  1]\n",
      " [ 5  2]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 1  0]\n",
      " [ 1  2]\n",
      " [ 1  6]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  6]\n",
      " [ 6  1]\n",
      " [ 6  2]\n",
      " [ 4  1]\n",
      " [ 4  2]\n",
      " [ 1  4]\n",
      " [ 1  2]\n",
      " [ 1  7]\n",
      " [ 2  4]\n",
      " [ 2  1]\n",
      " [ 2  7]\n",
      " [ 7  1]\n",
      " [ 7  2]\n",
      " [ 8  1]\n",
      " [ 8  9]\n",
      " [ 1  8]\n",
      " [ 1  9]\n",
      " [ 1 10]\n",
      " [ 9  8]\n",
      " [ 9  1]\n",
      " [ 9 10]\n",
      " [10  1]\n",
      " [10  9]\n",
      " [11  1]\n",
      " [11 12]\n",
      " [ 1 11]\n",
      " [ 1 12]\n",
      " [ 1 10]\n",
      " [12 11]\n",
      " [12  1]\n",
      " [12 10]\n",
      " [10  1]\n",
      " [10 12]\n",
      " [13  1]\n",
      " [13 14]\n",
      " [ 1 13]\n",
      " [ 1 14]\n",
      " [ 1 10]\n",
      " [14 13]\n",
      " [14  1]\n",
      " [14 10]\n",
      " [10  1]\n",
      " [10 14]]\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "idx_pairs = []\n",
    "# for each sentence\n",
    "for sentence in tokenized_corpus:\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    # for each word, threated as center word\n",
    "    for center_word_pos in range(len(indices)):\n",
    "        # for each window position\n",
    "        for w in range(-window_size, window_size + 1):\n",
    "            context_word_pos = center_word_pos + w\n",
    "            # make soure not jump out sentence\n",
    "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
    "                continue\n",
    "            context_word_idx = indices[context_word_pos]\n",
    "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
    "\n",
    "idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array\n",
    "print(idx_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_layer(word_idx):\n",
    "    x = torch.zeros(vocabulary_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-72d4d0159980>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0membedding_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_dims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Variable' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_dims = 5\n",
    "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
    "z1 = torch.matmul(W1, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
    "z2 = torch.matmul(W2, z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dims = 5\n",
    "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
    "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epo in range(num_epochs):\n",
    "    loss_val = 0\n",
    "    for data, target in idx_pairs:\n",
    "        x = Variable(get_input_layer(data)).float()\n",
    "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
    "\n",
    "        z1 = torch.matmul(W1, x)\n",
    "        z2 = torch.matmul(W2, z1)\n",
    "    \n",
    "        log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "        loss_val += loss.data[0]\n",
    "        loss.backward()\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "    if epo % 10 == 0:    \n",
    "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
